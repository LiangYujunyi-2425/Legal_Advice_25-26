import os
import pickle
import requests
import chromadb
from sentence_transformers import SentenceTransformer, CrossEncoder
from rank_bm25 import BM25Okapi
import jieba
from dotenv import load_dotenv

# ================== ç’°å¢ƒè®Šæ•¸ ==================
load_dotenv()

# ================== Embedding Function ==================
class GTEEmbeddingFunction:
    def __init__(self, model_name="thenlper/gte-large-zh"):
        print(f"ğŸ“¥ è¼‰å…¥æœ¬åœ°æ¨¡å‹ {model_name} ...")
        self.model = SentenceTransformer(model_name)
        self.model_name = model_name

    def __call__(self, input: list[str]) -> list[list[float]]:
        return self.model.encode(input, show_progress_bar=False).tolist()

    def name(self) -> str:
        return f"sentence-transformers/{self.model_name}"

# åˆå§‹åŒ–æ¨¡å‹
embedder = SentenceTransformer("thenlper/gte-large-zh")
reranker = CrossEncoder("BAAI/bge-reranker-large")

# ================== Chroma åˆå§‹åŒ– ==================
client = chromadb.PersistentClient(path="./chroma_db")
collection = client.get_or_create_collection(
    name="hk_cap4_laws",
    embedding_function=GTEEmbeddingFunction("thenlper/gte-large-zh")
)

# ================== BM25 (è¼‰å…¥ç´¢å¼•) ==================
if not os.path.exists("bm25_index.pkl"):
    raise FileNotFoundError("âŒ æ‰¾ä¸åˆ° bm25_index.pklï¼Œè«‹å…ˆåŸ·è¡Œ batch_cap4.py")

with open("bm25_index.pkl", "rb") as f:
    bm25_data = pickle.load(f)
bm25 = bm25_data["bm25"]
bm25_chunks = bm25_data["chunks"]

# ================== Gemini API ==================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("âŒ è«‹å…ˆåœ¨ .env è¨­å®š GEMINI_API_KEY")

GEMINI_MODEL = "gemini-1.5-flash"
GEMINI_ENDPOINT = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"
HEADERS = {"Content-Type": "application/json", "x-goog-api-key": GEMINI_API_KEY}

# ================== æª¢ç´¢ ==================
def hybrid_search(query: str, n=10):
    # 1. å‘é‡æª¢ç´¢
    vector_results = collection.query(
        query_texts=[query],
        n_results=n,
        include=["documents", "metadatas", "distances"]
    )
    vector_docs = vector_results["documents"][0]
    vector_metas = vector_results["metadatas"][0]
    vector_scores = vector_results["distances"][0]

    vector_candidates = [
        (doc, meta, 1 - score, "Chroma")
        for doc, meta, score in zip(vector_docs, vector_metas, vector_scores)
    ]

    # 2. BM25 æª¢ç´¢
    tokenized_query = list(jieba.cut(query))
    bm25_scores = bm25.get_scores(tokenized_query)
    top_idx = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:n]

    bm25_candidates = [
        (bm25_chunks[i]["text"], bm25_chunks[i], bm25_scores[i], "BM25") for i in top_idx
    ]

    # 3. åˆä½µ
    merged = {}
    for doc, meta, score, source in vector_candidates + bm25_candidates:
        if doc not in merged or score > merged[doc][1]:
            merged[doc] = (meta, score, source)

    return [(doc, meta, score, source) for doc, (meta, score, source) in merged.items()]

# ================== Rerank ==================
def rerank(query, candidates, top_k=3, debug=False):
    pairs = [(query, doc) for doc, _, _, _ in candidates]
    scores = reranker.predict(pairs)

    ranked = sorted(zip(candidates, scores), key=lambda x: x[1], reverse=True)

    if debug:
        print("\nğŸ“Š Debug - å€™é¸æª¢ç´¢åˆ†æ•¸å°æ¯”ï¼š")
        for (doc, meta, base_score, source), rerank_score in ranked[:10]:
            print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print(f"ä¾†æº: {source}")
            print(f"æ³•ä¾‹: {meta.get('law_name','')} {meta.get('section','')}")
            print(f"åˆå§‹åˆ†æ•¸: {base_score:.4f}")
            print(f"Reranker åˆ†æ•¸: {rerank_score:.4f}")
            print(f"æ¢æ–‡å…§å®¹: {doc[:80]}...")
        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")

    return ranked[:top_k]

# ================== Gemini å›ç­” ==================
def call_gemini(prompt):
    body = {
        "contents": [{"role": "user", "parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.2, "maxOutputTokens": 512}
    }

    resp = requests.post(GEMINI_ENDPOINT, headers=HEADERS, json=body)
    if resp.status_code != 200:
        return f"âš ï¸ Gemini è«‹æ±‚å¤±æ•—: {resp.status_code} {resp.text}"

    resp_data = resp.json()
    try:
        return resp_data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception:
        return str(resp_data)

def generate_answer_with_review(query, context_texts, sources):
    # Step 1: åˆç¨¿å›ç­”
    draft_prompt = (
        "ä½ æ˜¯ä¸€ä½é¦™æ¸¯æ³•å¾‹è¼”åŠ©åŠ©æ‰‹ã€‚æ ¹æ“šä»¥ä¸‹æ³•å¾‹æ¢æ–‡è¼”åŠ©å›ç­”å•é¡Œã€‚"
        "âš ï¸ è«‹å‹™å¿…ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚"
        "è«‹ç°¡æ½”æ¸…æ¥šè§£é‡‹ã€‚é€™ä¸æ˜¯æ³•å¾‹æ„è¦‹ã€‚\n\n"
        f"æ³•å¾‹æ¢æ–‡ï¼š\n{chr(10).join(context_texts)}\n\nå•é¡Œï¼š{query}"
    )
    draft_answer = call_gemini(draft_prompt)

    # Step 2: è¤‡æ ¸èˆ‡ä¿®æ­£
    review_prompt = (
        "ä»¥ä¸‹æ˜¯å¦ä¸€å€‹æ¨¡å‹çµ¦å‡ºçš„æ³•å¾‹å›ç­”è‰ç¨¿ã€‚"
        "è«‹å¹«æˆ‘æª¢æŸ¥ï¼š"
        "1. æ˜¯å¦å®Œæ•´æ¶µè“‹æ³•å¾‹æ¢æ–‡é‡é»ï¼Ÿ"
        "2. æ˜¯å¦å­˜åœ¨éŒ¯èª¤æˆ–å¹»è¦ºï¼Ÿ"
        "3. åœ¨ä¿æŒæº–ç¢ºæ€§çš„å‰æä¸‹ï¼Œè«‹å‹™å¿…ä»¥ç¹é«”ä¸­æ–‡è¼¸å‡ºæœ€çµ‚å›ç­”ã€‚\n\n"
        f"å•é¡Œï¼š{query}\n\nè‰ç¨¿å›ç­”ï¼š{draft_answer}"
    )
    final_answer = call_gemini(review_prompt)

    return f"{final_answer}\n\nğŸ“š ä¾†æºï¼š\n" + "\n".join(sources)

# ================== ä¸»ç¨‹å¼ ==================
if __name__ == "__main__":
    print("âœ… Hybrid RAG Pipeline 2.1 å·²å•Ÿå‹•ï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰")

    while True:
        query = input("\nâ“ è«‹è¼¸å…¥å•é¡Œ: ").strip()
        if query.lower() in ["exit", "quit", "q"]:
            print("ğŸ‘‹ å†è¦‹ï¼")
            break

        candidates = hybrid_search(query, n=10)
        reranked = rerank(query, candidates, top_k=3, debug=True)

        context_texts = [doc for (doc, _, _, _), _ in reranked]
        sources = [f"- {meta.get('law_name','')} {meta.get('section','')}" for (_, meta, _, _), _ in reranked]

        answer = generate_answer_with_review(query, context_texts, sources)
        print("\nğŸ§  Gemini æœ€çµ‚å›ç­”ï¼š")
        print(answer)
