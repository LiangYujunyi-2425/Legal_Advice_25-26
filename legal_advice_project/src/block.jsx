import { useState, forwardRef, useImperativeHandle, useRef, useEffect } from 'react';
import './index.css';
import xiaojinglin from './assets/xiaojinglin.webp';
import judgeAvatar from './assets/judge.webp';
import lawyerAvatar from './assets/lawyer.webp';
import ownerAvatar from './assets/owner.webp';
import managerAvatar from './assets/property_manager.webp';
import leaseMessages from './data/leaseMessages';
import welcomeSound from './assets/welcome.mp3';
import { streamPredict } from './api/predictClient';
import ReactMarkdown from 'react-markdown';
import rehypeRaw from 'rehype-raw';


// å±…ä¸­æ³¡æ³¡èŠå¤©ï¼ˆä¿ç•™ API / ä¸Šå‚³ é‚è¼¯ï¼‰ï¼Œå¸¶ banner æ³¢å‹•èˆ‡å³å´ AI è¡¨æƒ…äº’å‹•
const RightBlock = forwardRef(({ visible, setVisible, videoOpen, aiMood: propAiMood, setAiMood: propSetAiMood, voiceEnabled }, ref) => {
  const [messages, setMessages] = useState([]);
  const [input, setInput] = useState('');
  const [isIslandExpanded, setIsIslandExpanded] = useState(false);
  const [pendingPdfText, setPendingPdfText] = useState(null); // å¾…å‘é€çš„ PDF æ–‡æœ¬
  const API_URL = import.meta.env.VITE_API_URL || '';
  const inputRef = useRef(null);

  useImperativeHandle(ref, () => ({
    addMessage(role, content) {
      setMessages(prev => [...prev, { role, content }]);
    }
  }));

  const eyesRef = useRef(null);
  const overlayRef = useRef(null);
  const overlayScrollRef = useRef(null);
  const chatMessagesRef = useRef(null);
  const bubbleTimerRef = useRef(null);
  const playTimersRef = useRef([]);
  const [overlayMessagesState, setOverlayMessagesState] = useState([]);
  const [overlayParticipants, setOverlayParticipants] = useState([]);
  const [speakingAgentId, setSpeakingAgentId] = useState(null);

  const [squash, setSquash] = useState(false);
  const [aiMoodLocal, setAiMoodLocal] = useState('neutral'); // fallback local mood
  const aiMood = propAiMood || aiMoodLocal;
  const setAiMood = propSetAiMood || setAiMoodLocal;
  const [facePop, setFacePop] = useState(false);
  const [welcomeAudioAllowed, setWelcomeAudioAllowed] = useState(false);
  const [welcomeAudioError, setWelcomeAudioError] = useState(null);
  const welcomeAudioRef = useRef(null);
  const toggleVisible = () => {
    setVisible(prev => !prev);
    // å½“å¼¹çª—æ‰“å¼€æ—¶èšç„¦è¾“å…¥æ¡†å¹¶å±•å¼€çµåŠ¨å²›
    setTimeout(() => {
      if (!visible) {
        setIsIslandExpanded(true);
        setTimeout(() => inputRef.current?.focus(), 160);
      } else {
        setIsIslandExpanded(false);
      }
    }, 120);
  };

  // try auto-playing welcome audio on mount; if blocked, show a small play button
  useEffect(() => {
    let mounted = true;
    try {
      // use imported module path (Vite will resolve to correct URL)
      const a = new Audio(welcomeSound);
      a.preload = 'auto';
      welcomeAudioRef.current = a;
      const p = a.play();
      if (p && typeof p.then === 'function') {
        p.then(() => {
          if (!mounted) return;
          setWelcomeAudioAllowed(true);
        }).catch((err) => {
          if (!mounted) return;
          // autoplay blocked by browser policy
          setWelcomeAudioAllowed(false);
          setWelcomeAudioError(err?.message || 'blocked');
        });
      }
    } catch (e) {
      setWelcomeAudioAllowed(false);
      setWelcomeAudioError(e?.message || 'err');
    }

    return () => {
      mounted = false;
      try { welcomeAudioRef.current?.pause(); welcomeAudioRef.current = null; } catch (e) {}
    };
  }, []);


  // play conversation into the center overlay (è‡ªåŠ¨è§¦å‘äº sendMessage)
  const playConversation = (conversation = leaseMessages, speed = 900) => {
    // clear existing timers/intervals
    playTimersRef.current.forEach(t => clearTimeout(t));
    playTimersRef.current = [];
    setOverlayMessagesState([]);
    setAiMood('thinking');

    // hide/ç¼©å°ä¸­å¤®æ³¡æ³¡ä»¥å‘ˆç°ä¸­é—´å¯¹è¯ï¼ˆåœ†æ¡Œï¼‰
    setVisible(false);

    // build participants from conversation (unique speakers)
    const parts = [];
    const seen = new Set();
    conversation.messages.forEach(m => {
      const key = (m.avatarKey || m.role || m.speakerName || 'guest') + '::' + (m.speakerName || '');
      if (!seen.has(key)) {
        seen.add(key);
        parts.push({ id: Date.now() + Math.random(), avatarKey: m.avatarKey || m.role || 'lawyer', name: m.speakerName || m.role });
      }
    });
    setOverlayParticipants(parts);

    // helper: type one message char-by-char and animate speaker
    const typeMessage = (m, idx, perChar = 28) => {
      return new Promise((resolve) => {
        // add message entry with empty display text and alternating side (left/right)
        const side = (idx % 2 === 0) ? 'left' : 'right';
        setOverlayMessagesState(prev => [...prev, { id: m.id || Date.now() + idx, speaker: m.speakerName, role: m.role, text: '', avatarKey: m.avatarKey, side }]);
        // find participant id to map speaking animation
        const p = parts.find(p => (p.avatarKey === m.avatarKey) || (p.name === m.speakerName));
        const speakingId = p?.id || null;
        if (speakingId) setSpeakingAgentId(speakingId);

        // optionally trigger bubbles flow for certain roles
        if (['lawyer','judge','property_manager','owner'].includes(m.role)) {
          startBubblesFlow(m.text);
        }

        // gradually append characters
        const chars = Array.from(m.text || '');
        chars.forEach((ch, ci) => {
          const t = setTimeout(() => {
            setOverlayMessagesState(prev => {
              const copy = [...prev];
              const idxIn = copy.findIndex(x => x.id === (m.id || Date.now() + idx));
              if (idxIn !== -1) {
                copy[idxIn] = { ...copy[idxIn], text: copy[idxIn].text + ch };
              }
              return copy;
            });
            // small mood flicker
            setAiMood(ci % 2 === 0 ? 'thinking' : 'happy');
            // keep speaking animation active during typing
          }, ci * perChar);
          playTimersRef.current.push(t);
        });

        // finish after all chars
        const finishT = setTimeout(() => {
          setSpeakingAgentId(null);
          setAiMood('neutral');
          resolve();
        }, (chars.length * perChar) + 120);
        playTimersRef.current.push(finishT);
      });
    };

    // play messages sequentially
    (async () => {
      for (let i = 0; i < conversation.messages.length; i++) {
        const m = conversation.messages[i];
        try {
          await typeMessage(m, i, Math.max(20, Math.floor(speed / 30)));
        } catch (e) {
          // continue on error
        }
        // small pause between messages
        const pauseT = setTimeout(() => {}, 220);
        playTimersRef.current.push(pauseT);
        await new Promise(res => setTimeout(res, 220));
      }

      // done: compose final reply and restore
      setAiMood('neutral');
      const finalReply = (() => {
        try { return composeFinalReply(conversation); } catch { return 'å·²å®Œæˆè¨è«–ï¼Œè«‹åƒè€ƒä¸Šæ–¹è¦é»ã€‚'; }
      })();
      setMessages(prev => [...prev, { role: 'assistant', content: finalReply }]);
      // short delay then restore central bubble
      const endDelay = setTimeout(() => {
        setOverlayMessagesState([]);
        setOverlayParticipants([]);
        setVisible(true);
        playTimersRef.current = [];
      }, 800);
      playTimersRef.current.push(endDelay);
    })();
  };

  const avatarMap = {
    judge: judgeAvatar,
    lawyer: lawyerAvatar,
    owner: ownerAvatar,
    manager: managerAvatar,
  };

  // æ˜ å°„ç°¡å–® emojiï¼Œç”¨æ–¼å°è¡¨æƒ…æ³¡æ³¡
  const emoji = aiMood === 'happy' ? 'ğŸ˜Š'
    : aiMood === 'sad' ? 'ğŸ˜¢'
    : aiMood === 'thinking' ? 'ğŸ¤”'
    : aiMood === 'excited' ? 'ğŸ¤©'
    : 'ğŸ˜';

  // æ¯ç•¶ aiMood è®Šæ›´æ™‚è§¸ç™¼çŸ­æš«çš„ pop å‹•ç•«
  useEffect(() => {
    setFacePop(true);
    const t = setTimeout(() => setFacePop(false), 700);
    return () => clearTimeout(t);
  }, [aiMood]);

  useEffect(() => {
    // banner æ³¢åŠ¨ - æ¯å½“æœ‰æ–°æ¶ˆæ¯æ—¶è§¦å‘ä¸€æ¬¡æ³¢åŠ¨åŠ¨ç”»
    const banner = document.querySelector('.banner');
    if (!banner) return;
    banner.classList.add('wave');
    const t = setTimeout(() => banner.classList.remove('wave'), 700);
    return () => clearTimeout(t);
  }, [messages.length]);

  // ç›£è½ OCR åˆ†æçµæœäº‹ä»¶
  useEffect(() => {
    const handleOcrAnalysis = (event) => {
      const data = event.detail;
      if (!data) return;

      // å¦‚æœæœ‰ OCR æ–‡æœ¬ï¼Œå…ˆé¡¯ç¤ºè­˜åˆ¥çµæœ
      if (data.ocr_text) {
        const ocrMessage = `ğŸ” è­˜åˆ¥çš„æ–‡æœ¬ï¼š\n${data.ocr_text}`;
        setMessages(prev => [...prev, { role: 'assistant', content: ocrMessage }]);
      }

      // é¡¯ç¤º AI åˆ†æçµæœ
      if (data.summary) {
        const analysisMessage = `ğŸ“‹ åˆ†æçµæœï¼š\n${data.summary}`;
        setMessages(prev => [...prev, { role: 'assistant', content: analysisMessage }]);
      }

      // å¦‚æœæœ‰é¢¨éšªæç¤º
      if (data.risks && data.risks.length > 0) {
        const riskMessage = `âš ï¸ æ½›åœ¨é¢¨éšªï¼š\n${data.risks.join('\n')}`;
        setMessages(prev => [...prev, { role: 'assistant', content: riskMessage }]);
      }

      // æ‰“é–‹èŠå¤©çª—å£ä»¥é¡¯ç¤ºçµæœ
      try { setVisible(true); } catch (e) {}
    };

    window.addEventListener('ocr:analysisResult', handleOcrAnalysis);
    return () => window.removeEventListener('ocr:analysisResult', handleOcrAnalysis);
  }, [setVisible]);

  // ç›£è½ PDF æ–‡æœ¬æå–äº‹ä»¶ - å°†è¯†åˆ«çš„æ–‡æœ¬ç›´æ¥æ·»åŠ åˆ°èŠå¤©æ¡†
  useEffect(() => {
    const handlePdfTextExtracted = (event) => {
      const { detail } = event;
      if (!detail || !detail.text) return;

      const { text, source } = detail;
      
      // æ‰“é–‹èŠå¤©çª—å£
      try { setVisible(true); } catch (e) {}

      // å°†è¯†åˆ«çš„æ–‡æœ¬ä½œä¸ºç”¨æˆ·æ¶ˆæ¯è‡ªåŠ¨å‘é€
      console.log(`ğŸ“„ ä» ${source} æå–çš„æ–‡æœ¬ï¼Œè‡ªåŠ¨å‘é€åˆ°èŠå¤©:`, text.substring(0, 100) + '...');
      
      // å­˜å‚¨å¾…å‘é€çš„æ–‡æœ¬
      setPendingPdfText(text);
    };

    window.addEventListener('pdf:textExtracted', handlePdfTextExtracted);
    return () => window.removeEventListener('pdf:textExtracted', handlePdfTextExtracted);
  }, [setVisible]);

  // å¤„ç†å¾…å‘é€çš„ PDF æ–‡æœ¬ - åœ¨ sendMessage å®šä¹‰åè‡ªåŠ¨å‘é€
  useEffect(() => {
    if (!pendingPdfText) return;

    // å»¶è¿Ÿç¡®ä¿ UI å·²æ›´æ–°ï¼Œå†å°è¯•è‡ªåŠ¨å‘é€
    const timer = setTimeout(async () => {
      try {
        // ä¼˜å…ˆç›´æ¥è°ƒç”¨ sendMessage è‡ªåŠ¨å‘é€åˆ° AI
        if (typeof sendMessage === 'function') {
          await sendMessage(pendingPdfText);
        } else {
          // å›é€€ï¼šæŠŠæ–‡æœ¬å¡«å…¥è¾“å…¥æ¡†ä»¥ä¾¿æ‰‹åŠ¨å‘é€
          setInput(pendingPdfText);
          setTimeout(() => inputRef.current?.focus(), 100);
        }
      } catch (e) {
        console.error('è‡ªåŠ¨å‘é€ PDF æ–‡æœ¬å¤±è´¥ï¼Œå·²å›é€€è‡³è¾“å…¥æ¡†ï¼š', e);
        setInput(pendingPdfText);
        setTimeout(() => inputRef.current?.focus(), 100);
      } finally {
        setPendingPdfText(null);
      }
    }, 500);

    return () => clearTimeout(timer);
  }, [pendingPdfText]);

  // auto-scroll main chat to latest message
  useEffect(() => {
    try {
      const el = chatMessagesRef.current;
      if (el) el.scrollTop = el.scrollHeight;
    } catch (e) {
      // ignore
    }
  }, [messages.length]);

  // auto-scroll overlay chat to latest message
  useEffect(() => {
    try {
      const el = overlayScrollRef.current;
      if (el) el.scrollTop = el.scrollHeight;
    } catch (e) {
      // ignore
    }
  }, [overlayMessagesState.length]);

  // Random blink: add `blink` class to eyes group at random intervals
  useEffect(() => {
    let mounted = true;
    let timeoutId = null;

    const schedule = () => {
      const delay = 2000 + Math.random() * 6000; // 2-8s
      timeoutId = setTimeout(() => {
        if (!mounted) return;
        const eyes = eyesRef.current;
        if (!eyes) { schedule(); return; }
        eyes.classList.add('blink');
        // short blink
        setTimeout(() => {
          eyes.classList.remove('blink');
          if (mounted) schedule();
        }, 140);
      }, delay);
    };

    schedule();
    return () => {
      mounted = false;
      if (timeoutId) clearTimeout(timeoutId);
    };
  }, []);

  const sendMessage = async (textArg) => {
    const text = (typeof textArg === 'string' ? textArg : input).trim();
    if (!text) return;

    // push user message and a placeholder assistant message which we'll update while streaming
    const userMessage = { role: 'user', content: text };
    setMessages(prev => [...prev, userMessage, { role: 'assistant', content: 'AIåœ˜éšŠæ­£åœ¨åˆ†ææ‚¨çš„å•é¡Œâ€¦' }]);
    setInput('');
    setAiMood('thinking');
    setSquash(true);
    setTimeout(() => setSquash(false), 160);


    // Stream from remote predict endpoint and update assistant message incrementally
    (async () => {
      try {
        let accumulated = '';
        // collect multi-agent messages locally so we can act on them when stream ends
        const multiAgentMessages = [];
        for await (const chunk of streamPredict(text, false)) {
          if (chunk && typeof chunk === 'object' && chunk.agent) {
            const agentName = chunk.agent || 'Agent';
            const outputText = chunk.output || '';

            // å»ºç«‹ overlay message
            const m = {
              id: Date.now() + Math.random(),
              speaker: agentName,
              role: agentName,
              text: outputText,
              avatarKey: agentName.toLowerCase().includes('lawyer')
                ? 'lawyer'
                : agentName.toLowerCase().includes('prosecutor')
                ? 'judge'
                : 'xiaojinglin'
            };
            setOverlayMessagesState(prev => [...prev, m]);
            multiAgentMessages.push(m);

            setVisible(false);
            continue;
          }

          // ä¸€èˆ¬ assistant streaming
          let piece = typeof chunk === 'string' ? chunk : chunk?.output || JSON.stringify(chunk);
          accumulated += piece;
          setMessages(prev => {
            const copy = [...prev];
            copy[copy.length - 1] = { role: 'assistant', content: accumulated };
            return copy;
          });
        }

        // finished streaming
        if (multiAgentMessages.length > 0) {
          const lastAgent = multiAgentMessages[multiAgentMessages.length - 1];
          const rawText = lastAgent.text || '';
          const label = lastAgent.speaker ? `[${lastAgent.speaker}] ` : '';
          setMessages(prev => [...prev, { role: 'assistant', content: `${label}${rawText}` }]);

          setOverlayMessagesState([]);
          setOverlayParticipants([]);
          setVisible(true);
        }

        // compute last paragraph from accumulated stream and append as a focused assistant message
        try {
          const normalized = (accumulated || '').replace(/\r\n/g, '\n');
          const paragraphs = normalized.split(/\n{2,}/).map(p => p.trim()).filter(Boolean);
          const lastPara = paragraphs.length > 0 ? paragraphs[paragraphs.length - 1] : (normalized.trim() || '');
          if (lastPara) {
            setMessages(prev => [...prev, { role: 'assistant', content: lastPara }]);
          }
        } catch (e) {
          // ignore paragraph extraction errors
        }

        setAiMood('happy');
        setTimeout(() => setAiMood('neutral'), 900);
      } catch (err) {
        console.error('Predict stream error', err);
        setMessages(prev => {
          const copy = [...prev];
          copy[copy.length - 1] = { role: 'assistant', content: `âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š${String(err)}` };
          return copy;
        });
        setAiMood('sad');
        setTimeout(() => setAiMood('neutral'), 1200);
      } finally {
        setSquash(false);
      }
    })();
  };

  // Start bubble animation flow: create bubbles, position origin near latest user message,
  // keep them animating for 10s, then dismiss and re-open the dialog.
  const [bubblesActive, setBubblesActive] = useState(false);
  const [bubbles, setBubbles] = useState([]);

  const startBubblesFlow = (text) => {
    // create simple bubble placeholders
    const count = 5;
    const avatarKeys = Object.keys(avatarMap);
    const arr = Array.from({ length: count }).map((_, i) => ({
      id: Date.now() + i,
      text: 'æ€è€ƒâ€¦',
      delay: i * 0.12,
      angle: Math.random() * Math.PI * 2,
      dist: 80 + Math.random() * 120,
      avatarKey: avatarKeys[Math.floor(Math.random() * avatarKeys.length)],
    }));
    setBubbles(arr);
    setBubblesActive(true);

    // allow DOM æ›´æ–°åæ‰¾å‡ºåˆšå‘çš„ user æ¶ˆæ¯ä½ç½®ä½œä¸ºåŠ¨ç”»ä¸­å¿ƒ
    setTimeout(() => {
      try {
        const msgs = document.querySelectorAll('.chat-messages .message.user');
        const last = msgs[msgs.length - 1];
        let x = window.innerWidth / 2;
        let y = window.innerHeight / 2;
        if (last) {
          const r = last.getBoundingClientRect();
          x = r.left + r.width / 2;
          y = r.top + r.height / 2;
        }
        if (overlayRef.current) {
          overlayRef.current.style.setProperty('--origin-x', `${x}px`);
          overlayRef.current.style.setProperty('--origin-y', `${y}px`);
        }
      } catch (e) {
        // ignore
      }
    }, 80);

    // 10 ç§’åç»“æŸåŠ¨ç”»å¹¶æ¢å¤å¯¹è¯æ¡†
    if (bubbleTimerRef.current) clearTimeout(bubbleTimerRef.current);
    bubbleTimerRef.current = setTimeout(() => {
      setBubblesActive(false);
      setBubbles([]);
      setVisible(true);
    }, 10000);
  };

  useEffect(() => {
    return () => {
      if (bubbleTimerRef.current) clearTimeout(bubbleTimerRef.current);
    };
  }, []);

  // cleanup play timers on unmount
  useEffect(() => {
    return () => {
      playTimersRef.current.forEach(t => clearTimeout(t));
      playTimersRef.current = [];
    };
  }, []);

  const uploadFile = async (event) => {
    const file = event.target.files?.[0];
    if (!file) return;

    try {
      setAiMood('excited');
      // æ³¨ï¼šåç«¯ API åªæœ‰ /predict ç«¯ç‚¹ï¼Œä¸æ”¯æŒ /analyze
      // æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½å·²åœ¨ Title.jsx ä¸­é€šè¿‡ OCR å¤„ç†
      alert('åˆåŒåˆ†æåŠŸèƒ½å·²é›†æˆåˆ° PDF/å›¾ç‰‡ä¸Šä¼ æµç¨‹ä¸­ã€‚è¯·é€šè¿‡å·¦ä¾§é¢æ¿ä¸Šä¼  PDF æˆ–æ‹ç…§ã€‚');
      setAiMood('neutral');
    } catch (error) {
      console.error('å¤„ç†å¤±è´¥', error);
      setMessages(prev => [
        ...prev,
        { role: 'assistant', content: 'âŒ æ–‡ä»¶åˆ†æå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚' }
      ]);
      setAiMood('sad');
      setTimeout(() => setAiMood('neutral'), 1200);
    }
  };

  // ---------------- Camera Scanner (è¾¹æ¡†å¼•å¯¼ + è¾¹ç¼˜æ£€æµ‹ + é˜²æŠ–è‡ªåŠ¨æ‹æ‘„) ----------------
  // Camera scanner feature removed per request.

  // --- Web Speech API: è¯­éŸ³è¯†åˆ« (å…¼å®¹ webkit) ---
  const [recognizing, setRecognizing] = useState(false);
  const [selectedLang, setSelectedLang] = useState('yue-HK'); // é»˜è®¤ç²¤è¯­
  const recognitionRef = useRef(null);
  const supportsSpeech = typeof window !== 'undefined' && (window.SpeechRecognition || window.webkitSpeechRecognition);

  useEffect(() => {
    if (!supportsSpeech) return;
    const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
    const rec = new SR();
    rec.lang = selectedLang;
    rec.interimResults = true;
    rec.continuous = false;
    rec.maxAlternatives = 1;

    rec.onresult = (ev) => {
      try {
        let interim = '';
        let finalTrans = '';
        for (let i = ev.resultIndex; i < ev.results.length; ++i) {
          const res = ev.results[i];
          const t = (res[0] && res[0].transcript) ? res[0].transcript : '';
          if (res.isFinal) finalTrans += t;
          else interim += t;
        }
        if (finalTrans) {
          const combined = (input ? input + ' ' : '') + finalTrans;
          setInput(combined);
          // small delay to ensure state update then send
          setTimeout(() => sendMessage(combined), 80);
        } else {
          const combined = (input ? input + ' ' : '') + interim;
          setInput(combined);
        }
      } catch (e) {
        console.warn('speech onresult error', e);
      }
    };

    rec.onerror = (e) => {
      console.warn('SpeechRecognition error', e);
      setRecognizing(false);
    };

    rec.onend = () => {
      setRecognizing(false);
    };

    recognitionRef.current = rec;
    return () => {
      try { recognitionRef.current?.abort(); } catch (e) {}
      recognitionRef.current = null;
    };
  }, [selectedLang]);

  const startRecognition = () => {
    if (!supportsSpeech) {
      setWelcomeAudioError('èªéŸ³è¾¨è­˜ä¸æ”¯æ´æ–¼æ­¤ç€è¦½å™¨');
      return;
    }
    try {
      recognitionRef.current.lang = selectedLang;
      recognitionRef.current.start();
      setRecognizing(true);
    } catch (e) {
      // try to recover
      try { recognitionRef.current?.abort(); recognitionRef.current?.start(); setRecognizing(true); } catch (e2) { setWelcomeAudioError(e2?.message || String(e2)); }
    }
  };

  const stopRecognition = () => {
    try { recognitionRef.current?.stop(); } catch (e) {}
    setRecognizing(false);
  };

  // å½“ä¸­å¤®æ³¡æ³¡ï¼ˆvisibleï¼‰æ‰“å¼€æ—¶ï¼Œä¸”ä½¿ç”¨è€…å·²å¼€å¯æ™ºèƒ½èªéŸ³è¼”åŠ©ï¼ˆvoiceEnabledï¼‰æ‰ä¼šè‡ªåŠ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«ï¼›å…³é—­æˆ–å…³é—­è¯­éŸ³è¾…åŠ©æ—¶åœæ­¢ã€‚
  // æ³¨æ„ï¼šæŸäº›æµè§ˆå™¨è¦æ±‚ç”¨æˆ·æ‰‹åŠ¿æ‰èƒ½å¼€å¯éº¦å…‹é£è®¿é—®ï¼Œè‹¥è¢«æµè§ˆå™¨é˜»æ­¢ï¼Œç”¨æˆ·éœ€æ‰‹åŠ¨ç‚¹å‡»è¯­éŸ³æŒ‰é’®ã€‚
  useEffect(() => {
    if (visible && voiceEnabled) {
      try { startRecognition(); } catch (e) { /* ignore */ }
    } else {
      try { stopRecognition(); } catch (e) { /* ignore */ }
    }
  }, [visible, voiceEnabled]);

  // --- Text-to-Speech: ç”¨æ–¼è®€å‡º assistant å›è¦†ï¼Œå„ªå…ˆé¸æ“‡å»£æ±è©±/HK è²éŸ³ ---
  // é»˜è®¤å…è®¸ TTSï¼Œä½†ä» localStorage è¯»å–ç”¨æˆ·åå¥½ä»¥ä¾¿è®°ä½å¼€å…³çŠ¶æ€
  const [ttsEnabled, setTtsEnabled] = useState(() => {
    try {
      const v = localStorage.getItem('ttsEnabled');
      return v === null ? true : v === 'true';
    } catch (e) {
      return true;
    }
  });
  const toggleTts = () => {
    setTtsEnabled(prev => {
      const next = !prev;
      try { localStorage.setItem('ttsEnabled', String(next)); } catch (e) {}
      return next;
    });
  };
  const ttsVoicesRef = useRef([]);
  const ttsVoiceRef = useRef(null);

  useEffect(() => {
    if (typeof window === 'undefined' || !('speechSynthesis' in window)) return;
    const loadVoices = () => {
      try {
        const vs = window.speechSynthesis.getVoices() || [];
        ttsVoicesRef.current = vs;
        // prefer voices that indicate Cantonese or Hong Kong
        const pref = vs.find(v => (v.lang && v.lang.toLowerCase().includes('yue')) || (v.lang && v.lang.toLowerCase().includes('hk')) || (v.name && v.name.toLowerCase().includes('canton')));
        const zhPref = vs.find(v => v.lang && v.lang.toLowerCase().startsWith('zh'));
        ttsVoiceRef.current = pref || zhPref || vs[0] || null;
      } catch (e) {
        // ignore
      }
    };

    loadVoices();
    // some browsers load voices asynchronously
    window.speechSynthesis.onvoiceschanged = loadVoices;
    return () => { try { window.speechSynthesis.onvoiceschanged = null; } catch (e) {} };
  }, []);

  const speakText = (text) => {
    if (!ttsEnabled) return;
    if (typeof window === 'undefined' || !('speechSynthesis' in window)) return;
    try {
      // stop any ongoing recognition to avoid mic feedback during TTS
      try { stopRecognition(); } catch (e) { /* ignore */ }
      window.speechSynthesis.cancel();
      const u = new SpeechSynthesisUtterance(text);
      const v = ttsVoiceRef.current;
      if (v) u.voice = v;
      // ensure language hints; some voices require correct lang
      u.lang = (v && v.lang) ? v.lang : 'zh-HK';
      u.rate = 1;
      u.pitch = 1;
      u.onstart = () => { try { setAiMood('excited'); } catch (e) {} };
      u.onend = () => {
        try { setAiMood('neutral'); } catch (e) {}
        // After speech finished, attempt to restart recognition if supported
        try {
          if (supportsSpeech && visible) {
            // small delay to avoid racing with other UI updates
            setTimeout(() => {
              try { startRecognition(); } catch (e) { /* ignore start errors (may require user gesture) */ }
            }, 260);
          }
        } catch (e) { /* ignore */ }
      };
      u.onerror = () => { try { setAiMood('neutral'); } catch (e) {} };
      window.speechSynthesis.speak(u);
    } catch (e) {
      // ignore TTS errors
      console.warn('TTS error', e);
    }
  };

  // å½“æœ‰æ–°çš„ assistant æ¶ˆæ¯æ—¶è‡ªåŠ¨è¯»å‡ºï¼ˆç²¤è¯­ä¼˜å…ˆï¼‰
  useEffect(() => {
    if (!messages || !messages.length) return;
    const last = messages[messages.length - 1];
    if (last && last.role === 'assistant' && last.content) {
      // small delay to avoid racing with animations
      setTimeout(() => speakText(last.content), 120);
    }
  }, [messages.length]);

  // ç›‘å¬å…¨å±€è¯­éŸ³å‘½ä»¤äº‹ä»¶ï¼ˆç”± useVoiceCommands å‘å‡ºï¼‰
  useEffect(() => {
    const onOpenUpload = (e) => {
      try {
        // ç¡®ä¿ä¸­å¤®æ³¡æ³¡æ‰“å¼€å¹¶æ”¾å¤§ä»¥ä¾¿ä½¿ç”¨è€…çœ‹åˆ°ä¸Šä¼ åŒºåŸŸ
        try { setVisible(true); } catch (err) {}
        try { setIsIslandExpanded(true); } catch (err) {}
        // ç­‰å¾…çŸ­æš«æ™‚é–“è®“ DOM æ›´æ–°ä¸¦èšç„¦ï¼Œå†è§¸ç™¼æª”æ¡ˆè¼¸å…¥
        setTimeout(() => {
          try {
            const inp = document.getElementById('rb-file-input') || document.querySelector('.file-input');
            if (inp) inp.click();
          } catch (e) { /* ignore */ }
        }, 140);
      } catch (err) { /* ignore */ }
    };
    const onOpenAi = (e) => {
      try {
        setVisible(true);
        // focus input when opening
        setTimeout(() => {
          const el = document.querySelector('.chat-input input[type="text"]');
          if (el) el.focus();
        }, 120);
      } catch (err) { /* ignore */ }
    };
    const onGoHome = (e) => { try { window.location.hash = '#/'; } catch (err) {} };

    window.addEventListener('voice:open-upload', onOpenUpload);
    window.addEventListener('voice:open-ai', onOpenAi);
    window.addEventListener('voice:go-home', onGoHome);
    return () => {
      window.removeEventListener('voice:open-upload', onOpenUpload);
      window.removeEventListener('voice:open-ai', onOpenAi);
      window.removeEventListener('voice:go-home', onGoHome);
    };
  }, [setVisible]);

  return (
    <>
      {/* æµ®å‹•å³ä¸‹é–‹é—œ */}
      <button
        className={`openbutt island ${isIslandExpanded ? 'expanded' : ''}`}
        onClick={toggleVisible}
        aria-label="é–‹å•ŸèŠå¤©"
      >
        <div className="island-content">
          <div className="dot" />
        </div>
      </button>

      {/* ä¸­å¤®æ³¡æ³¡å°è©±æ¡† */}
  <div className={`center-overlay ${visible ? 'visible' : 'hidden'}`} onClick={() => setVisible(false)} />
  <div className={`center-bubble ${visible ? 'open' : 'closed'} ${squash ? 'squash' : ''} ${videoOpen ? 'compressed' : ''}`} role="dialog" aria-hidden={!visible}>
        <div className={`bubble-header ${isIslandExpanded ? 'stretch' : ''}`} onClick={(e) => { e.stopPropagation(); setIsIslandExpanded(s => !s); }}>
          <div className="header-left">
            <div className="avatar-bubble" />
            <div className="title">æ³•å¾‹åŠ©ç†</div>
          </div>
          <div className="header-right">
            {messages.length} è¨Šæ¯
          </div>
        </div>

        <div className="chat-container">
          <div className="chat-messages" ref={chatMessagesRef}>
            {messages.map((msg, index) => (
              <div key={index} className={`message ${msg.role}`}>
                <ReactMarkdown rehypePlugins={[rehypeRaw]}>
                  {msg.content}
                </ReactMarkdown>
              </div>
            ))}
          </div>

          <div className="chat-input" style={{ display: 'flex', alignItems: 'center', gap: 8 }}>
            <button
              className={`mic-button ${recognizing ? 'recording' : ''}`}
              onMouseDown={(e) => { e.preventDefault(); startRecognition(); }}
              onMouseUp={(e) => { e.preventDefault(); stopRecognition(); }}
              onTouchStart={(e) => { e.preventDefault(); startRecognition(); }}
              onTouchEnd={(e) => { e.preventDefault(); stopRecognition(); }}
              onClick={(e) => { e.preventDefault(); if (!recognizing) startRecognition(); else stopRecognition(); }}
              title={supportsSpeech ? `æŒ‰ä½èªªè©± (æˆ–é»æ“Šé–‹å§‹/åœæ­¢)ã€‚èªè¨€: ${selectedLang}` : 'ç€è¦½å™¨ä¸æ”¯æ´èªéŸ³è¾¨è­˜'}
              style={{ padding: '6px 10px', borderRadius: 8, border: '1px solid rgba(0,0,0,0.08)',fontSize: '18px',fontWeight: 'bold' ,background: recognizing ? '#e74c3c' : undefined, color: recognizing ? '#fff' : undefined }}
            >
              {recognizing ? 'â— éŒ„éŸ³ä¸­â€¦' : 'ğŸ¤ èªéŸ³'}
            </button>

            <select value={selectedLang} onChange={(e) => setSelectedLang(e.target.value)} aria-label="é¸æ“‡èªè¨€" style={{ padding: 6, borderRadius: 6 }}>
              <option value="yue-HK">ç²¤è¯­ (yue-HK)</option>
              <option value="zh-HK">ç¹ä¸­-é¦™æ¸¯ (zh-HK)</option>
              <option value="zh-CN">æ™®é€šè¯ (zh-CN)</option>
              <option value="en-US">English (en-US)</option>
            </select>

            <input
              ref={inputRef}
              type="text"
              value={input}
              onChange={(e) => setInput(e.target.value)}
              onKeyDown={(e) => e.key === 'Enter' && sendMessage()}
              placeholder="å•æˆ‘æœ‰é—œåˆåŒæˆ–æ³•å¾‹çš„å•é¡Œ..."
              style={{ flex: 1, padding: '8px 10px', borderRadius: 8, border: '1px solid rgba(0,0,0,0.08)' }}
            />

            <button className='ai_txt_sendbutton' onClick={() => sendMessage()} >é€å‡º</button>

            {/* TTS å¼€å…³ï¼šé»˜è®¤å¼€å¯ï¼Œç‚¹å‡»å¯å…³é—­/å¼€å¯å¹¶æŒä¹…åŒ– */}
            <button
              className='ai_txt_sendbutton'
              onClick={(e) => { e.stopPropagation(); toggleTts(); }}
              title={ttsEnabled ? 'èªéŸ³æ’­å ±ï¼šé–‹å•Ÿï¼ˆé»æ“Šé—œé–‰ï¼‰' : 'èªéŸ³æ’­å ±ï¼šé—œé–‰ï¼ˆé»æ“Šé–‹å•Ÿï¼‰'}
            >
              {ttsEnabled ? 'ğŸ”Š èªéŸ³é–‹' : 'ğŸ”‡ èªéŸ³é—œ'}
            </button>


            <label className="file-label" style={{ marginLeft: 4 }}>
              ğŸ“
              <input id="rb-file-input" className="file-input" type="file" accept="application/pdf" onChange={uploadFile} />
            </label>
          </div>
        </div>
      </div>
      {/* AI è¡¨æƒ…ï¼ˆè·Ÿéš¨å°è©±æƒ…ç·’è®ŠåŒ–ï¼‰ï¼Œè‹¥æ‹ç…§æ¨¡å¼ä¸­å‰‡éš±è— */}
      {/* Camera Scanner removed */}
      <div className="ai-face-outer" aria-hidden={!visible || videoOpen}>
        {!videoOpen && (
          <div
            className={`ai-face ${facePop ? 'pop' : ''} ${aiMood}`}
            ref={eyesRef}
            style={{ position: 'fixed', left: '13%', top: '50px' }}
          >
            <img
              src={xiaojinglin}
              alt="AI è¡¨æƒ…"
              style={{ width: '96px', height: '96px', objectFit: 'cover', display: 'block' }}
            />
            <span className="expression" aria-hidden="true">{emoji}</span>
          </div>
        )}
      </div>
      {/* welcome éŸ³é »æ‰‹å‹•æ’­æ”¾æŒ‰éˆ•ï¼ˆåœ¨ autoplay è¢«é˜»æ­¢æ™‚é¡¯ç¤ºï¼‰ */}
      {!welcomeAudioAllowed && (
        <button
          className="welcome-play"
          onClick={async (e) => {
            e.stopPropagation();
            try {
              await welcomeAudioRef.current?.play();
              setWelcomeAudioAllowed(true);
              setWelcomeAudioError(null);
            } catch (err) {
              setWelcomeAudioError(err?.message || 'play failed');
            }
          }}
          style={{ position: 'fixed', right: 18, top: 18, zIndex: 200 }}
        >
          â–¶ï¸ æ’­æ”¾æ­¡è¿èªéŸ³
        </button>
      )}
      {/* åœ†æ¡Œä¼šè¯ overlayï¼ˆRound-tableï¼‰ */}
      <div className="roundtable-overlay" style={{ display: overlayMessagesState.length ? 'flex' : 'none' }} aria-hidden={!overlayMessagesState.length}>
        <div className="roundtable-card">
          <div className="roundtable-agents" aria-hidden="false">
            {overlayParticipants.map((p, i) => {
              // position agents evenly around circle
              const spacing = 900; // æ¯å€‹ agent çš„æ°´å¹³é–“è·
              const startX = `calc(50% - ${(overlayParticipants.length - 1) * spacing / 2}px)`;
              const left = `calc(${startX} + ${i * spacing}px)`;
              const top = `60%`; // å›ºå®šåœ¨ç•«é¢ä¸­ä¸‹æ–¹
              const isSpeaking = speakingAgentId === p.id;
              return (
                <div key={p.id} className={`agent-node ${isSpeaking ? 'agent-speaking' : ''} ${isSpeaking ? 'agent-stretch' : ''}`} style={{ left, top }}>
                  <img src={avatarMap[p.avatarKey] || xiaojinglin} alt={p.name} />
                  <div className="name">{p.name}</div>
                </div>
              );
            })}
          </div>

          <div className={`roundtable-center ${speakingAgentId ? 'agent-active' : ''}`} role="dialog" aria-label="åœ“æ¡Œæœƒè­°">
            <div className="center-title">æ³•å¾‹ç²¾éˆåœ“æ¡Œæœƒè­°</div>
            <div className="center-text" ref={overlayScrollRef}>
              {overlayMessagesState.map((m, mi) => (
                <div key={m.id} className={`rt-message ${m.side === 'left' ? 'msg-left' : 'msg-right'}`} style={{ marginBottom: 10 }}>
                  <div className={`rt-avatar`}>
                    <img src={avatarMap[m.avatarKey] || xiaojinglin} alt={m.speaker} style={{ width: 36, height: 36, borderRadius: 18 }} />
                  </div>
                  {/* floating sender name placed near avatar and animated per-side */}
                  <div className="rt-sender-floating">{m.speaker}</div>
                  <div className={`rt-body`}>
                    <div className={`center-message`}>
                      <ReactMarkdown rehypePlugins={[rehypeRaw]}>
                        {m.text}
                      </ReactMarkdown>
                    </div>
                  </div>
                </div>
              ))}
            </div>
          </div>
        </div>
      </div>

      {/* æ³¡æ³¡åŠ¨ç”»è¦†ç›–å±‚ï¼ˆå‘é€æ¶ˆæ¯æ—¶è§¦å‘ï¼‰ */}
      <div className="bubbles-overlay" ref={overlayRef} aria-hidden={!bubblesActive} style={{ display: bubblesActive ? 'block' : 'none' }}>
        <div className="bubbles-container">
          {bubbles.map((b, i) => {
            const tx = Math.cos(b.angle) * b.dist;
            const ty = Math.sin(b.angle) * b.dist;
            const style = { '--tx': `${tx}px`, '--ty': `${ty}px`, left: 0, top: 0 };
            return (
              <div key={b.id} className={`bubble-agent ${bubblesActive ? 'show' : ''}`} style={style}>
                  <div className="orb">
                    <img src={avatarMap[b.avatarKey] || xiaojinglin} alt="agent" />
                  </div>
                <div className="btext">{b.text}</div>
              </div>
            );
          })}
        </div>
      </div>
    </>
  );
});

export default RightBlock;