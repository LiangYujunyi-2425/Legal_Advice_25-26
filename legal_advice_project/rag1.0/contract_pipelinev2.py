import os
import re
import json
from datetime import datetime
from docx import Document
from dotenv import load_dotenv

from contract_ingest import load_contract, split_into_clauses
from vertexai import rag
from vertexai.generative_models import Tool, GenerativeModel

# ==========================
# ç’°å¢ƒè®Šæ•¸
# ==========================
load_dotenv()
PROJECT_ID = os.getenv("GCP_PROJECT")
LOCATION = os.getenv("GCP_LOCATION", "us-central1")
RAG_CORPUS_NAME = os.getenv("RAG_CORPUS_NAME")  # ä½ è¦åœ¨ .env è¨­å®šé€™å€‹å€¼

if not PROJECT_ID or not RAG_CORPUS_NAME:
    raise ValueError("âŒ è«‹åœ¨ .env è¨­å®š GCP_PROJECT èˆ‡ RAG_CORPUS_NAME")

REPORTS_DIR = "./reports"
os.makedirs(REPORTS_DIR, exist_ok=True)

# ==========================
# åˆå§‹åŒ– Vertex AI RAG
# ==========================
rag_retrieval_config = rag.RagRetrievalConfig(
    top_k=3,
    filter=rag.Filter(vector_distance_threshold=0.5)
)

rag_tool = Tool.from_retrieval(
    retrieval=rag.Retrieval(
        source=rag.VertexRagStore(
            rag_resources=[rag.RagResource(rag_corpus=RAG_CORPUS_NAME)],
            rag_retrieval_config=rag_retrieval_config
        )
    )
)

# ç¬¬ä¸€å±¤ Geminiï¼ˆç”Ÿæˆåˆç¨¿ï¼‰
rag_model_primary = GenerativeModel(
    model_name="gemini-2.0-flash-001",
    tools=[rag_tool]
)

# ç¬¬äºŒå±¤ Geminiï¼ˆè¤‡æ ¸ç­”æ¡ˆï¼‰
rag_model_reviewer = GenerativeModel(
    model_name="gemini-2.0-flash-001"
)

# ==========================
# æ¸…ç†è¼¸å‡ºï¼Œç§»é™¤å†—é¤˜å­—çœ¼
# ==========================
def clean_output(text: str) -> str:
    if not text:
        return ""
    # ç§»é™¤å¸¸è¦‹é–‹é ­
    text = re.sub(r"^ä»¥ä¸‹æ˜¯.*\n?", "", text)
    text = re.sub(r"^å¥½çš„ï¼Œæˆ‘ä¾†.*\n?", "", text)
    # ç§»é™¤ã€Œä¿®æ­£èªªæ˜ã€ã€ã€Œä¿®æ­£å¾Œã€ç­‰å­—çœ¼
    text = text.replace("ä¿®æ­£èªªæ˜åŠç†ç”±ï¼š", "")
    text = text.replace("ä¿®æ­£å¾Œçš„é¢¨éšªåˆ†æï¼š", "")
    text = text.replace("ä¿®æ­£å¾Œçš„æ‘˜è¦ï¼š", "")
    text = text.replace("ä¿®æ­£å¾Œçš„åˆ†æï¼š", "")
    return text.strip()

# ==========================
# æ¢æ¬¾åˆ†æï¼ˆä½¿ç”¨ RAG + è¤‡æ ¸ï¼‰
# ==========================
def analyze_clause(clause_text: str):
    try:
        # åˆç¨¿
        prompt_primary = f"""
è«‹åˆ†æä»¥ä¸‹åˆç´„æ¢æ¬¾ï¼š

æ¢æ¬¾å…§å®¹ï¼š
{clause_text[:800]}

è«‹æä¾›ï¼š
1. æ¢æ¬¾è¦é»
2. æ½›åœ¨é¢¨éšª
3. æ³•å¾‹ä¾æ“š
"""
        draft = rag_model_primary.generate_content(prompt_primary).text.strip()

        # è¤‡æ ¸ï¼ˆè¦æ±‚ä¹¾æ·¨è¼¸å‡ºï¼‰
        prompt_review = f"""
ä½ æ˜¯ä¸€ä½åš´è¬¹çš„æ³•å¾‹å¯©æ ¸åŠ©æ‰‹ã€‚è«‹ç›´æ¥è¼¸å‡ºæœ€çµ‚åˆ†æå…§å®¹ï¼Œä¸è¦åŒ…å«ã€Œä»¥ä¸‹æ˜¯ã€ã€ã€Œä¿®æ­£èªªæ˜ã€ã€ã€Œä¿®æ­£å¾Œã€ç­‰å­—çœ¼ï¼Œä¹Ÿä¸è¦æè¿°å¯©æ ¸éç¨‹ã€‚

æ¢æ¬¾å…§å®¹ï¼š
{clause_text[:800]}

åˆæ­¥åˆ†æï¼š
{draft}

è«‹è¼¸å‡ºä¹¾æ·¨ã€æ­£å¼çš„æœ€çµ‚åˆ†æï¼š
"""
        final = rag_model_reviewer.generate_content(prompt_review).text.strip()
        return clean_output(final)

    except Exception as e:
        print(f"âŒ æ¢æ¬¾åˆ†æéŒ¯èª¤: {e}")
        return f"æ¢æ¬¾åˆ†æå¤±æ•—: {str(e)}"

# ==========================
# å…¨å±€åˆç´„åˆ†æï¼ˆä½¿ç”¨ RAG + è¤‡æ ¸ï¼‰
# ==========================
def analyze_contract_global(contract_text: str):
    limited_text = contract_text[:6000]

    summary_prompt = f"""
è«‹åˆ†æä»¥ä¸‹åˆç´„å…§å®¹ï¼Œæä¾›ç°¡æ½”çš„æ‘˜è¦ï¼š
1. åˆç´„é¡å‹å’Œç›®çš„
2. ä¸»è¦ç•¶äº‹äºº
3. æ ¸å¿ƒæ¢æ¬¾è¦é»

åˆç´„å…§å®¹ï¼š
{limited_text}
"""
    risk_prompt = f"""
è«‹åˆ†æä»¥ä¸‹åˆç´„å…§å®¹ï¼Œè­˜åˆ¥æ½›åœ¨é¢¨éšªï¼š
1. æ³•å¾‹é¢¨éšª
2. å•†æ¥­é¢¨éšª
3. åŸ·è¡Œé¢¨éšª

åˆç´„å…§å®¹ï¼š
{limited_text}
"""

    print("ğŸ” ç”Ÿæˆåˆç´„æ‘˜è¦...")
    draft_summary = rag_model_primary.generate_content(summary_prompt).text.strip()
    summary_review_prompt = f"""
ä½ æ˜¯ä¸€ä½åš´è¬¹çš„æ³•å¾‹å¯©æ ¸åŠ©æ‰‹ã€‚è«‹ç›´æ¥è¼¸å‡ºæœ€çµ‚æ‘˜è¦ï¼Œä¸è¦åŒ…å«ã€Œä»¥ä¸‹æ˜¯ã€ã€ã€Œä¿®æ­£èªªæ˜ã€ã€ã€Œä¿®æ­£å¾Œã€ç­‰å­—çœ¼ã€‚

åˆç´„å…§å®¹ï¼š
{limited_text[:1000]}...

åˆç¨¿æ‘˜è¦ï¼š
{draft_summary}

è«‹è¼¸å‡ºä¹¾æ·¨ã€æ­£å¼çš„æœ€çµ‚æ‘˜è¦ï¼š
"""
    summary = rag_model_reviewer.generate_content(summary_review_prompt).text.strip()
    summary = clean_output(summary)

    print("âš ï¸ åˆ†ææ½›åœ¨é¢¨éšª...")
    draft_risks = rag_model_primary.generate_content(risk_prompt).text.strip()
    risks_review_prompt = f"""
ä½ æ˜¯ä¸€ä½åš´è¬¹çš„æ³•å¾‹å¯©æ ¸åŠ©æ‰‹ã€‚è«‹ç›´æ¥è¼¸å‡ºæœ€çµ‚é¢¨éšªåˆ†æï¼Œä¸è¦åŒ…å«ã€Œä»¥ä¸‹æ˜¯ã€ã€ã€Œä¿®æ­£èªªæ˜ã€ã€ã€Œä¿®æ­£å¾Œã€ç­‰å­—çœ¼ã€‚

åˆç´„å…§å®¹ï¼š
{limited_text[:1000]}...

åˆç¨¿é¢¨éšªåˆ†æï¼š
{draft_risks}

è«‹è¼¸å‡ºä¹¾æ·¨ã€æ­£å¼çš„æœ€çµ‚é¢¨éšªåˆ†æï¼š
"""
    risks = rag_model_reviewer.generate_content(risks_review_prompt).text.strip()
    risks = clean_output(risks)

    return {"summary": summary, "risks": risks}

# ==========================
# å ±å‘Šè¼¸å‡º
# ==========================
def generate_word_report(filename, summary, risks, clause_analyses):
    doc = Document()
    doc.add_heading("åˆç´„åˆ†æå ±å‘Š", level=1)

    doc.add_heading("ğŸ“Œ åˆç´„æ‘˜è¦", level=2)
    doc.add_paragraph(summary if summary else "ç„¡æ‘˜è¦")

    doc.add_heading("âš ï¸ æ½›åœ¨é¢¨éšª", level=2)
    if risks:
        for r in risks.split("\n"):
            doc.add_paragraph(f"- {r.strip()}")
    else:
        doc.add_paragraph("æœªæª¢æ¸¬åˆ°æ˜é¡¯é¢¨éšªã€‚")

    doc.add_heading("ğŸ“‘ æ¢æ¬¾é€æ¢åˆ†æ", level=2)
    for i, (clause, analysis) in enumerate(clause_analyses, 1):
        doc.add_heading(f"æ¢æ¬¾ {i}", level=3)
        doc.add_paragraph(clause, style="Intense Quote")
        doc.add_paragraph(f"ğŸ” åˆ†æ: {analysis}")

    base_name = os.path.basename(filename)
    out_name = base_name.rsplit(".", 1)[0] + "_åˆ†æ.docx"
    out_path = os.path.join(REPORTS_DIR, out_name)
    doc.save(out_path)
    return out_path

def save_json_report(filename, summary, risks, clause_analyses):
    data = {
        "generated_at": datetime.now().isoformat(),
        "summary": summary,
        "risks": risks.split("\n") if isinstance(risks, str) else risks,
        "clauses": [{"clause": c, "analysis": a} for c, a in clause_analyses]
    }

    base_name = os.path.basename(filename)
    out_name = base_name.rsplit(".", 1)[0] + "_åˆ†æ.json"
    out_path = os.path.join(REPORTS_DIR, out_name)

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return out_path

# ==========================
# ä¸»æµç¨‹ï¼šæƒæ contracts/
# ==========================
def analyze_contract_file(file_path):
    print(f"\nğŸš€ é–‹å§‹åˆ†æåˆç´„ï¼š{file_path}")
    text = load_contract(file_path)
    clauses = split_into_clauses(text, max_len=600)

    clause_analyses = []
    for i, clause in enumerate(clauses, 1):
        print(f"ğŸ” æ¢æ¬¾ {i} åˆ†æä¸­...")
        analysis = analyze_clause(clause)
        clause_analyses.append((clause, analysis))

    global_analysis = analyze_contract_global(text)
    summary, risks = global_analysis["summary"], global_analysis["risks"]

    word_file = generate_word_report(file_path, summary, risks, clause_analyses)
    json_file = save_json_report(file_path, summary, risks, clause_analyses)

    print(f"âœ… å ±å‘Šå®Œæˆï¼š{word_file}, {json_file}")
    return {
        "word": word_file,
        "json": json_file,
        "summary": summary,
        "risks": risks,
        "clauses": clause_analyses
    }

if __name__ == "__main__":
    contracts_dir = "./contracts"
    for filename in os.listdir(contracts_dir):
        file_path = os.path.join(contracts_dir, filename)
        if os.path.isfile(file_path) and filename.lower().endswith((".pdf", ".docx", ".txt")):
            analyze_contract_file(file_path)
