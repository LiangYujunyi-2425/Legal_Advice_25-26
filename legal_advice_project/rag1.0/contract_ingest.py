import os
import re
import pdfplumber
import docx
import chromadb
from sentence_transformers import SentenceTransformer

# ================== Embedding Function ==================
class GTEEmbeddingFunction:
    def __init__(self, model_name="thenlper/gte-large-zh"):
        print(f"ğŸ“¥ è¼‰å…¥æœ¬åœ°æ¨¡å‹ {model_name} ...")
        self.model = SentenceTransformer(model_name)

    def __call__(self, input: list[str]) -> list[list[float]]:
        return self.model.encode(input, show_progress_bar=False).tolist()

    def name(self) -> str:
        return "thenlper/gte-large-zh"


# ================== æ–‡ä»¶è§£æ ==================
def load_contract(file_path):
    text = ""
    if file_path.endswith(".pdf"):
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
    elif file_path.endswith(".docx"):
        doc = docx.Document(file_path)
        for para in doc.paragraphs:
            text += para.text + "\n"
    elif file_path.endswith(".txt"):
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read()
    else:
        raise ValueError("âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼ï¼ˆåƒ…æ”¯æ´ PDF / DOCX / TXTï¼‰")
    return re.sub(r"\s+", " ", text).strip()


# ================== Chunking ==================
def split_into_clauses(text, max_len=500):
    clauses = re.split(r"[ã€‚ï¼›\n]", text)
    chunks = []
    buffer = ""
    for clause in clauses:
        if len(buffer) + len(clause) > max_len:
            chunks.append(buffer.strip())
            buffer = clause
        else:
            buffer += " " + clause
    if buffer:
        chunks.append(buffer.strip())
    return chunks


# ================== å­˜å…¥ ChromaDB ==================
def save_contract(file_path, contract_name="contract"):
    client = chromadb.PersistentClient(path="./chroma_db")
    collection = client.get_or_create_collection(
        name="contracts",
        embedding_function=GTEEmbeddingFunction("thenlper/gte-large-zh")
    )

    text = load_contract(file_path)
    chunks = split_into_clauses(text, max_len=500)

    for i, chunk in enumerate(chunks):
        meta = {"contract": contract_name, "clause_id": i}
        collection.add(
            documents=[chunk],
            metadatas=[meta],
            ids=[f"{contract_name}_{i}"]
        )

    print(f"âœ… å·²å°‡ {len(chunks)} å€‹æ¢æ¬¾å­˜å…¥ contracts collection")


# ================== ä¸»ç¨‹å¼ ==================
if __name__ == "__main__":
    file_path = input("ğŸ“‚ è«‹è¼¸å…¥åˆç´„æª”æ¡ˆè·¯å¾‘ (PDF/DOCX/TXT): ").strip()

    if not os.path.exists(file_path):
        print("âŒ æ‰¾ä¸åˆ°æª”æ¡ˆï¼Œè«‹ç¢ºèªè·¯å¾‘æ˜¯å¦æ­£ç¢º")
    else:
        # è‡ªå‹•ç”¨æª”åä½œç‚ºåˆç´„åç¨±
        contract_name = os.path.splitext(os.path.basename(file_path))[0]
        save_contract(file_path, contract_name=contract_name)
